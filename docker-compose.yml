# docker-compose.yml (Final, Robust, GPU-Enabled)

volumes:
  mysql_data:
  hf_cache:

networks:
  llm_toolkit_net:
    driver: bridge

services:
  webapp:
    build:
      context: .
      dockerfile: Dockerfile
      target: dev-gpu
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    extra_hosts:
      - "host.docker.internal:host-gateway"
    ports:
      - "5001:5000"
    volumes:
      - ./app:/app/app
      - ./wsgi.py:/app/wsgi.py
      - hf_cache:/root/.cache/huggingface
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - DATABASE_URL=mysql+pymysql://${MYSQL_USER}:${MYSQL_PASSWORD}@db/${MYSQL_DATABASE}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - TARGET_API_ENDPOINT=${TARGET_API_ENDPOINT}
      - TARGET_LLM_API_KEY=${TARGET_LLM_API_KEY}
      - NIM_API_KEY=${NIM_API_KEY}
      - HF_TOKEN=${HF_TOKEN}
      - HF_HOME=/root/.cache/huggingface
      - OLLAMA_API_ENDPOINT=${OLLAMA_API_ENDPOINT}
      - SMART_CLASSIFIER_MODEL_NAME=${SMART_CLASSIFIER_MODEL_NAME}
      - LLAMA_GUARD_ENDPOINT=${LLAMA_GUARD_ENDPOINT}
      - LLAMA_GUARD_MODEL=${LLAMA_GUARD_MODEL}
      - FLASK_SECRET_KEY=${FLASK_SECRET_KEY}
      - APP_ADMIN_PASSWORD=${APP_ADMIN_PASSWORD}
    depends_on:
      db:
        condition: service_healthy
    #restart: always
    networks:
      - llm_toolkit_net

  db:
    image: mysql:8.0
    command: --default-authentication-plugin=mysql_native_password
    ports: ["3307:3306"]
    environment:
      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD}
      MYSQL_DATABASE: ${MYSQL_DATABASE}
      MYSQL_USER: ${MYSQL_USER}
      MYSQL_PASSWORD: ${MYSQL_PASSWORD}
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "${MYSQL_USER}", "-p${MYSQL_PASSWORD}"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s
    volumes:
      - mysql_data:/var/lib/mysql
    #restart: always
    networks:
      - llm_toolkit_net
    
      
  redis:
    image: "redis:alpine"
    ports: ["6379:6379"]
    networks:
      - llm_toolkit_net

  worker:
    build:
      context: .
      dockerfile: Dockerfile
    # The worker also needs access to the GPU if it runs ML tasks
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    command: dramatiq --threads 2 app.dramatiq_setup
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - ./app:/app/app
      - hf_cache:/root/.cache/huggingface
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - DATABASE_URL=mysql+pymysql://${MYSQL_USER}:${MYSQL_PASSWORD}@db/${MYSQL_DATABASE}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - NIM_API_KEY=${NIM_API_KEY}
      - HF_TOKEN=${HF_TOKEN}
      - HF_HOME=/root/.cache/huggingface
      - OLLAMA_API_ENDPOINT=${OLLAMA_API_ENDPOINT}
      - SMART_CLASSIFIER_MODEL_NAME=${SMART_CLASSIFIER_MODEL_NAME}
      - LLAMA_GUARD_ENDPOINT=${LLAMA_GUARD_ENDPOINT}
      - LLAMA_GUARD_MODEL=${LLAMA_GUARD_MODEL}
      - FLASK_SECRET_KEY=${FLASK_SECRET_KEY}
      - APP_ADMIN_PASSWORD=${APP_ADMIN_PASSWORD}
    depends_on:
      redis:
        condition: service_started
      db:
        condition: service_healthy
    #restart: unless-stopped # Use unless-stopped for workers
    networks:
      - llm_toolkit_net

