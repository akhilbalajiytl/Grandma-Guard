# .github/workflows/ci_pipeline.yml

name: LLM Safety Toolkit CI

# This section defines WHEN the pipeline runs.
# It will trigger on any push to the 'master' branch.
on:
  push:
    branches: [ "master" ]
  pull_request:
    branches: [ "master" ]

jobs:
  # --- JOB 1: LINTING ---
  # This job is for fast code quality checks.
  lint:
    runs-on: ubuntu-latest  # Use a standard Linux runner
    steps:
      # Step 1: Check out the repository code so the runner has access to it.
      - name: Check out repository
        uses: actions/checkout@v4

      # Step 2: Set up a Python environment.
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11' # Use the same Python version as your Dockerfile

      # Step 3: Install dependencies needed for linting.
      - name: Install linting dependencies
        run: pip install flake8

      # Step 4: Run the linter.
      # The flake8 command will scan your 'app' directory for issues.
      # If it finds any major errors, it will exit with a non-zero code, failing the job.
      - name: Run flake8 linter
        run: flake8 app

  # --- JOB 2: INTEGRATION TEST ---
  # This job runs your full application using Docker Compose.
  integration-test:
    runs-on: ubuntu-latest
    # This job will only run if the 'lint' job succeeds.
    needs: lint
    
    # We need to grant permissions for the token used in the docker/login-action
    permissions:
      contents: read
      packages: write

    # Define the environment variables for the job, just like in the manual workflow.
    env:
      CI: true
      MYSQL_USER: ci_user
      MYSQL_PASSWORD: ci_password
      MYSQL_DATABASE: ci_db
      MYSQL_ROOT_PASSWORD: ci_root_password
      # Add the cache path variable definition
      HF_CACHE_PATH: /home/runner/.cache/huggingface

    steps:
      # Step 1: Check out the repository code.
      - name: Check out repository
        uses: actions/checkout@v4

       # Add the caching step for Hugging Face models.
      - name: Cache Hugging Face models
        uses: actions/cache@v4
        with:
          path: ${{ env.HF_CACHE_PATH }}
          key: ${{ runner.os }}-hf-ci-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-hf-ci-

      # Step 2: Set up Docker Buildx (an advanced builder for Docker)
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      # Step 3: Build and start the services using Docker Compose.
      # We run it in detached mode (-d) so the next step can execute.
      # The 'CI=true' environment variable is used by your run_cli.py script.
      # This step now inherits the env vars and works correctly.
      - name: Build and run Docker Compose
        run: |
          mkdir -p ${{ env.HF_CACHE_PATH }}
          docker compose up --build -d

      # Step 4: Wait for the services to be healthy.
      # It's important to wait for the database to be ready before running the scan.
      - name: Wait for services to be ready
        run: |
          echo "Waiting for database to be ready..."
          # We'll use a simple loop to wait until the webapp container can connect to the db port
          # This command will retry every 5 seconds, up to 12 times (1 minute total).
          i=0
          while ! docker compose exec -T webapp sh -c 'nc -z db 3306' >/dev/null 2>&1; do
            i=$((i+1))
            if [ $i -ge 12 ]; then
              echo "Database did not become available in time."
              docker-compose logs db
              exit 1
            fi
            echo -n "."
            sleep 5
          done
          echo "Database is ready!"

      # Step 5: Run the CLI Scan
      # We execute the run_cli.py script inside the running 'webapp' container.
      # We use a simple test model that doesn't require an API key to avoid managing secrets in CI for now.
      # The Garak 'test.Blank' generator just returns empty strings.
      # --- SUMMARY FIX: Correctly run the scan and save the log ---
      # We wrap the command in 'bash -c' to ensure the pipe and tee command work correctly.
      - name: Run CLI scan against a test model
        run: |
          bash -c '
            docker compose exec -T \
              -e CI=true \
              -e DATABASE_URL="sqlite:///ci_scan_results.db" \
              -e OPENAI_API_KEY="ci-dummy-key-for-judge" \
              webapp python run_cli.py \
                --model-name "CI Test Run" \
                --api-endpoint "http://test-endpoint" \
                --api-key "test-key" \
                --openai-model "garak:test.Blank" \
            | tee ci_scan_output.log
          '
      
      # This 'Publish Test Summary' step will now work correctly
      - name: Publish Test Summary
        # This step only runs if the scan step before it succeeded
        if: success()
        run: |
          score_line=$(grep 'Score:' ci_scan_output.log | tail -n 1)
          if [ -z "$score_line" ]; then
              score_line="Score: Not found"
          fi
          echo "### 🛡️ LLM Safety Toolkit: Integration Test" >> $GITHUB_STEP_SUMMARY
          echo "**Commit:** ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "**Result:** ✅ CI Scan Completed" >> $GITHUB_STEP_SUMMARY
          echo "**Final Score:** \`${score_line}\`" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "<details><summary>Click to view full scan log</summary>" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          cat ci_scan_output.log >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "</details>" >> $GITHUB_STEP_SUMMARY

      - name: Display container logs on failure
        if: failure()
        run: docker compose logs