# ==============================================================================
# GRANDMAGUARD CONTINUOUS INTEGRATION PIPELINE
# ==============================================================================
#
# Purpose: Automated CI/CD pipeline for code quality and integration testing
#
# This workflow provides continuous integration for the GrandmaGuard security
# scanning system. It automatically runs on code changes to ensure quality,
# functionality, and security standards are maintained.
#
# Pipeline Stages:
# 1. Code Quality (Linting) - Fast feedback on code style and syntax
# 2. Integration Testing - Full application testing with containerized services
#
# Key Features:
# - Automatic triggering on pushes and pull requests to master branch
# - Multi-stage pipeline with dependency management (lint â†’ test)
# - Docker containerization for consistent testing environment
# - Artifact collection for debugging and analysis
# - Comprehensive test reporting and summaries
# - Container registry caching for performance optimization
#
# Security Considerations:
# - Isolated CI environment with non-production credentials
# - Container isolation for security testing operations
# - Safe handling of dummy API keys and test data
#
# Maintenance Notes:
# - Keep Python version in sync with production Dockerfile
# - Update linting rules and CI dependencies as needed
# - Monitor cache effectiveness and adjust retention policies
# - Review test coverage and add new test scenarios as needed
# ==============================================================================

name: LLM Safety Toolkit CI

# ==============================================================================
# TRIGGER CONFIGURATION
# ==============================================================================
# Defines when this CI pipeline should execute automatically
on:
  push:
    branches: [ "master" ]     # Run on pushes to master branch
  pull_request:
    branches: [ "master" ]     # Run on pull requests targeting master

jobs:
  # ============================================================================
  # JOB 1: CODE QUALITY AND LINTING
  # ============================================================================
  # Fast code quality checks to provide immediate feedback on code style,
  # syntax errors, and basic quality issues before running expensive tests
  lint:
    runs-on: ubuntu-latest
    
    steps:
      # Step 1: Source Code Access
      # Download repository content to the runner environment
      - name: Check out repository
        uses: actions/checkout@v4

      # Step 2: Python Environment Setup
      # Configure Python runtime matching production environment
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'  # Keep in sync with Dockerfile Python version

      # Step 3: Linting Dependencies Installation
      # Install only the tools needed for code quality checks
      - name: Install linting dependencies
        run: pip install flake8

      # Step 4: Code Quality Analysis
      # Run flake8 linter to check for:
      # - Syntax errors and undefined names
      # - Code style violations (PEP 8)
      # - Complexity issues and potential bugs
      - name: Run flake8 linter
        run: flake8 app

  # ============================================================================
  # JOB 2: INTEGRATION TESTING
  # ============================================================================
  # Comprehensive integration testing using full containerized environment
  # This job validates the complete application stack functionality
  integration-test:
    runs-on: ubuntu-latest
    
    # Job Dependencies: Only run if linting passes
    # This ensures we don't waste resources on broken code
    needs: lint
    
    # Required Permissions for Container Operations
    permissions:
      contents: read      # Read repository content
      packages: write     # Write to GitHub Container Registry for caching

    # Environment Configuration for CI Testing
    # Uses separate CI-specific values to isolate from staging/production
    env:
      CI: true                    # Flag to enable CI-specific behavior
      
      # MySQL Database Configuration (CI Environment)
      MYSQL_USER: ci_user
      MYSQL_PASSWORD: ci_password
      MYSQL_DATABASE: ci_db
      MYSQL_ROOT_PASSWORD: ci_root_password
      
      # Cache and Build Configuration
      HF_CACHE_PATH: /home/runner/.cache/huggingface
      
      # Docker Image Tagging Strategy for CI
      # Separate namespace to avoid conflicts with staging/production
      WEBAPP_IMAGE_OVERRIDE: llm-safety-toolkit-ci:ci-${{ github.run_id }}
      CACHE_IMAGE_PATH: ghcr.io/${{ github.repository_owner }}/llm-safety-toolkit-ci

    steps:
      # ==================================================================
      # STEP 1: SOURCE CODE CHECKOUT
      # ==================================================================
      - name: Check out repository
        uses: actions/checkout@v4

      # ==================================================================
      # STEP 2: REPORTS DIRECTORY SETUP
      # ==================================================================
      # Ensure output directory exists for CI artifacts
      - name: Create Reports Directory
        run: mkdir -p ./reports_output

      # ==================================================================
      # STEP 3: HUGGING FACE MODEL CACHING
      # ==================================================================
      # Cache ML models with CI-specific cache key to avoid conflicts
      - name: Cache Hugging Face models
        uses: actions/cache@v4
        with:
          path: ${{ env.HF_CACHE_PATH }}
          key: ${{ runner.os }}-hf-ci-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-hf-ci-

      # ==================================================================
      # STEP 4: DOCKER BUILDX SETUP
      # ==================================================================
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      # ==================================================================
      # STEP 5: CONTAINER REGISTRY AUTHENTICATION
      # ==================================================================
      - name: Log in to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      # ==================================================================
      # STEP 6: DOCKER IMAGE BUILD AND CACHE
      # ==================================================================
      # Build application image with CI-specific caching strategy
      - name: Build and Cache Docker image
        uses: docker/build-push-action@v5
        with:
            context: .                                     # Build context
            target: production                             # Dockerfile target stage
            push: false                                    # Don't push image to registry
            load: true                                     # Load into local Docker daemon
            tags: ${{ env.WEBAPP_IMAGE_OVERRIDE }}       # CI-specific image tag
            # Registry cache configuration for CI performance
            cache-from: type=registry,ref=${{ env.CACHE_IMAGE_PATH }}:buildcache
            cache-to: type=registry,ref=${{ env.CACHE_IMAGE_PATH }}:buildcache,mode=max

      # ==================================================================
      # STEP 7: CONTAINERIZED SERVICES STARTUP
      # ==================================================================
      # Start all required services (webapp + database) using compose files
      # This creates the complete testing environment
      - name: Start Services
        run: docker compose -f docker-compose.yml -f docker-compose.ci.yml up -d
        env:
          WEBAPP_IMAGE_OVERRIDE: ${{ env.WEBAPP_IMAGE_OVERRIDE }}

      # ==================================================================
      # STEP 8: SERVICE READINESS VERIFICATION
      # ==================================================================
      # Wait for database to be fully ready before running tests
      # This prevents race conditions and connection failures
      - name: Wait for services to be ready
        run: |
          echo "Waiting for database to be ready..."
          i=0
          # Use temporary container to check database connectivity
          while ! docker compose -f docker-compose.yml run --rm webapp sh -c 'nc -z db 3306' >/dev/null 2>&1; do
            i=$((i+1))
            if [ $i -ge 12 ]; then
              echo "Database did not become available in time."
              docker-compose -f docker-compose.yml logs db
              exit 1
            fi
            echo -n "."
            sleep 5
          done
          echo "Database is ready!"
        env:
            WEBAPP_IMAGE_OVERRIDE: ${{ env.WEBAPP_IMAGE_OVERRIDE }}

      # ==================================================================
      # STEP 9: CI SECURITY SCAN EXECUTION
      # ==================================================================
      # Execute security scan using test model and dummy credentials
      # This validates the core functionality without external API dependencies
      - name: Run CLI scan against a test model
        run: |
          set -o pipefail
          # Execute scan inside running webapp container
          # Uses dummy/test endpoints to avoid external dependencies in CI
          docker compose -f docker-compose.yml exec -T \
            -e CI=true \
            -e DATABASE_URL="sqlite:///ci_scan_results.db" \
            -e OPENAI_API_KEY="ci-dummy-key-for-judge" \
            --workdir /app \
            webapp bash -c "mkdir -p reports && python run_cli.py \
              --scan-name 'CI Test Run' \
              --api-endpoint 'http://test-endpoint' \
              --api-key 'test-key' \
              --openai-model 'garak:test.Blank'" \
          | tee ci_scan_output.log
        env:
            WEBAPP_IMAGE_OVERRIDE: ${{ env.WEBAPP_IMAGE_OVERRIDE }}

      # ==================================================================
      # STEP 10: CI ARTIFACT COLLECTION
      # ==================================================================
      # Upload scan results for debugging and analysis
      # Runs even if scan fails to help with troubleshooting
      - name: Upload Scan Report Artifact
        uses: actions/upload-artifact@v4
        if: always()  # Upload even if the scan step fails, to help with debugging
        with:
          name: ci-scan-report
          # Upload scan log for CI analysis
          # Full reports would require additional container file copying
          path: ci_scan_output.log
          retention-days: 7
      
      # ==================================================================
      # STEP 11: CI TEST SUMMARY GENERATION
      # ==================================================================
      # Create formatted test summary for GitHub Actions UI
      # Provides quick visibility into CI test results
      - name: Publish Test Summary
        if: success()  # Only run if all previous steps succeeded
        run: |
          # Extract security score from scan output
          score_line=$(grep 'Score:' ci_scan_output.log | tail -n 1)
          if [ -z "$score_line" ]; then
              score_line="Score: Not found"
          fi
          
          # Generate GitHub Actions summary report
          echo "### ðŸ›¡ï¸ LLM Safety Toolkit: Integration Test" >> $GITHUB_STEP_SUMMARY
          echo "**Commit:** ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "**Result:** âœ… CI Scan Completed" >> $GITHUB_STEP_SUMMARY
          echo "**Final Score:** \`${score_line}\`" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "<details><summary>Click to view full scan log</summary>" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          cat ci_scan_output.log >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "</details>" >> $GITHUB_STEP_SUMMARY

      # ==================================================================
      # STEP 12: FAILURE DEBUGGING AND DIAGNOSTICS
      # ==================================================================
      # Display container logs when CI fails for debugging
      - name: Display container logs on failure
        if: failure()
        run: docker compose logs