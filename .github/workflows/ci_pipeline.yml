# .github/workflows/ci_pipeline.yml

name: LLM Safety Toolkit CI

# This section defines WHEN the pipeline runs.
# It will trigger on any push to the 'master' branch.
on:
  push:
    branches: [ "master" ]
  pull_request:
    branches: [ "master" ]

jobs:
  # --- JOB 1: LINTING ---
  # This job is for fast code quality checks.
  lint:
    runs-on: ubuntu-latest  # Use a standard Linux runner
    steps:
      # Step 1: Check out the repository code so the runner has access to it.
      - name: Check out repository
        uses: actions/checkout@v4

      # Step 2: Set up a Python environment.
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11' # Use the same Python version as your Dockerfile

      # Step 3: Install dependencies needed for linting.
      - name: Install linting dependencies
        run: pip install flake8

      # Step 4: Run the linter.
      # The flake8 command will scan your 'app' directory for issues.
      # If it finds any major errors, it will exit with a non-zero code, failing the job.
      - name: Run flake8 linter
        run: flake8 app

  # --- JOB 2: INTEGRATION TEST ---
  # This job runs your full application using Docker Compose.
  integration-test:
    runs-on: ubuntu-latest
    # This job will only run if the 'lint' job succeeds.
    needs: lint
    
    # We need to grant permissions for the token used in the docker/login-action
    permissions:
      contents: read
      packages: write

    steps:
      # Step 1: Check out the repository code.
      - name: Check out repository
        uses: actions/checkout@v4

      # Step 2: Set up Docker Buildx (an advanced builder for Docker)
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      # Step 3: Build and start the services using Docker Compose.
      # We run it in detached mode (-d) so the next step can execute.
      # The 'CI=true' environment variable is used by your run_cli.py script.
      - name: Build and run Docker Compose
        env:
          CI: true # This tells your run_cli.py to use the SQLite DB
          MYSQL_USER: ci_user
          MYSQL_PASSWORD: ci_password
          MYSQL_DATABASE: ci_db
          MYSQL_ROOT_PASSWORD: ci_root_password
        run: docker compose up --build -d

      # Step 4: Wait for the services to be healthy.
      # It's important to wait for the database to be ready before running the scan.
      - name: Wait for services to be ready
        run: |
          echo "Waiting for database to be ready..."
          # We'll use a simple loop to wait until the webapp container can connect to the db port
          # This command will retry every 5 seconds, up to 12 times (1 minute total).
          i=0
          while ! docker compose exec -T webapp sh -c 'nc -z db 3306' >/dev/null 2>&1; do
            i=$((i+1))
            if [ $i -ge 12 ]; then
              echo "Database did not become available in time."
              docker-compose logs db
              exit 1
            fi
            echo -n "."
            sleep 5
          done
          echo "Database is ready!"

      # Step 5: Run the CLI Scan
      # We execute the run_cli.py script inside the running 'webapp' container.
      # We use a simple test model that doesn't require an API key to avoid managing secrets in CI for now.
      # The Garak 'test.Blank' generator just returns empty strings.
      - name: Run CLI scan against a test model
        run: >
          docker compose exec -T
          -e CI=true
          webapp python run_cli.py
          --model-name "CI Test Run"
          --api-endpoint "http://test-endpoint"
          --api-key "test-key"
          --openai-model "garak:test.Blank" # Use Garak's blank generator

      # Step 6: Check the logs if the scan failed
      # This step only runs if the previous step (the scan) failed.
      - name: Display container logs on failure
        if: failure()
        run: docker compose logs