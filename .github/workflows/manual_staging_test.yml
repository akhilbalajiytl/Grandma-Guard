# .github/workflows/manual_staging_test.yml

name: Manual Staging Test

on:
  workflow_dispatch:

jobs:
  staging-test:
    runs-on: ubuntu-latest
    
    env:
      MYSQL_USER: staging_user
      MYSQL_PASSWORD: staging_password
      MYSQL_DATABASE: staging_db
      MYSQL_ROOT_PASSWORD: staging_root_password
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      HF_CACHE_PATH: /home/runner/.cache/huggingface

    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Cache Hugging Face models
        uses: actions/cache@v4
        with:
          path: ${{ env.HF_CACHE_PATH }}
          key: ${{ runner.os }}-hf-${{ hashFiles('**/requirements.txt') }}

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      # --- THIS IS THE NEW STRATEGY ---
      # Step 1: Build all images first
      - name: Build Docker images
        run: docker compose build

      # Step 2: Start ONLY the database service
      - name: Start Database Service
        run: docker compose up -d db

      # Step 3: Wait for the database to be healthy
      - name: Wait for Database
        run: |
          echo "Waiting for database to be ready..."
          # This command waits for the 'db' container to report 'healthy'
          # It will time out after 2 minutes if the DB isn't ready.
          docker compose wait -t 120s db
          echo "Database is ready!"
      
      # Step 4: Run the scan using 'docker compose run'
      # This creates a new container just for our test script. It does NOT
      # use the entrypoint.sh or start gunicorn.
      - name: Run Scan via docker compose run
        run: |
          bash -c '
            docker compose run --rm \
              -e CI=true \
              -e DATABASE_URL="mysql+pymysql://staging_user:staging_password@db/staging_db" \
              -e OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }} \
              webapp python run_cli.py \
                --model-name "Staging Test: GPT-3.5-Turbo" \
                --api-endpoint "https://api.openai.com/v1/chat/completions" \
                --api-key "${{ secrets.OPENAI_API_KEY }}" \
                --openai-model "gpt-3.5-turbo" \
            | tee staging_scan_output.log
          '
          
      # Step 6: Publish the Job Summary from the log file
      - name: Publish Test Summary
        if: success()
        run: |
          score_line=$(grep 'Score:' staging_scan_output.log | tail -n 1)
          if [ -z "$score_line" ]; then
              score_line="Score: Not found"
          fi
          echo "### 🛡️ LLM Safety Toolkit: Manual Staging Test" >> $GITHUB_STEP_SUMMARY
          echo "**Commit:** ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "**Result:** ✅ Real Scan Completed" >> $GITHUB_STEP_SUMMARY
          echo "**Final Score:** \`${score_line}\`" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "<details><summary>Click to view full scan log</summary>" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          cat staging_scan_output.log >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "</details>" >> $GITHUB_STEP_SUMMARY

      # Step 7: Display logs only if a step failed
      - name: Display container logs on failure
        if: failure()
        run: docker compose logs