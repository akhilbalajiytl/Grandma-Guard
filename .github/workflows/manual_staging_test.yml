# .github/workflows/manual_staging_test.yml

name: Manual Staging Test

on:
  workflow_dispatch:

jobs:
  staging-test:
    runs-on: ubuntu-latest
    
    # We only need the secrets at the job level.
    env:
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      # We hardcode the known path for the cache. This is reliable.
      - name: Cache Hugging Face models
        uses: actions/cache@v4
        with:
          path: /home/runner/.cache/huggingface
          key: ${{ runner.os }}-hf-${{ hashFiles('**/requirements.txt') }}

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      # --- THIS IS THE DEFINITIVE FIX ---
      - name: Build and run Docker Compose
        # We pass the static MYSQL variables directly to this step.
        env:
          MYSQL_USER: staging_user
          MYSQL_PASSWORD: staging_password
          MYSQL_DATABASE: staging_db
          MYSQL_ROOT_PASSWORD: staging_root_password
        run: |
          # Use the literal, hardcoded path. This cannot fail due to variable expansion.
          CACHE_DIR="/home/runner/.cache/huggingface"
          mkdir -p $CACHE_DIR
          
          # Pass this path directly into the docker-compose command's own environment.
          HF_CACHE=$CACHE_DIR docker compose up --build -d

      # Step 4: Wait for services to be ready
      - name: Wait for services
        run: |
          echo "Waiting for database..."
          i=0
          while ! docker compose exec -T webapp sh -c 'nc -z db 3306' >/dev/null 2>&1; do
            i=$((i+1))
            if [ $i -ge 12 ]; then
              echo "Database did not become available in time."
              docker compose logs db
              exit 1
            fi
            echo -n "."
            sleep 5
          done
          echo "Database is ready!"

      # Step 5: Run the REAL scan and save the output to a log file
      - name: Run REAL scan against GPT-3.5-Turbo
        run: |
          bash -c '
            docker compose exec -T \
              -e CI=true \
              -e DATABASE_URL="sqlite:///ci_scan_results.db" \
              -e OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }} \
              webapp python run_cli.py \
                --model-name "Staging Test: GPT-3.5-Turbo" \
                --api-endpoint "https://api.openai.com/v1/chat/completions" \
                --api-key "${{ secrets.OPENAI_API_KEY }}" \
                --openai-model "gpt-3.5-turbo" \
            | tee staging_scan_output.log
          '
          
      # Step 6: Publish the Job Summary from the log file
      - name: Publish Test Summary
        if: success()
        run: |
          score_line=$(grep 'Score:' staging_scan_output.log | tail -n 1)
          if [ -z "$score_line" ]; then
              score_line="Score: Not found"
          fi
          echo "### 🛡️ LLM Safety Toolkit: Manual Staging Test" >> $GITHUB_STEP_SUMMARY
          echo "**Commit:** ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "**Result:** ✅ Real Scan Completed" >> $GITHUB_STEP_SUMMARY
          echo "**Final Score:** \`${score_line}\`" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "<details><summary>Click to view full scan log</summary>" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          cat staging_scan_output.log >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "</details>" >> $GITHUB_STEP_SUMMARY

      # Step 7: Display logs only if a step failed
      - name: Display container logs on failure
        if: failure()
        run: docker compose logs