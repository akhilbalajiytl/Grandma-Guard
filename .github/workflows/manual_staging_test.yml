# .github/workflows/manual_staging_test.yml

name: Manual Staging Test

on:
  workflow_dispatch:

jobs:
  staging-test:
    runs-on: ubuntu-latest
    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      # --- HUGGING FACE CACHE ---
      - name: Cache Hugging Face models
        uses: actions/cache@v4
        with:
          path: ~/.cache/huggingface
          key: ${{ runner.os }}-hf-${{ hashFiles('**/requirements.txt') }}

      # --- PRE-LOAD MODELS ON HOST ---
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Install dependencies on host
        run: pip install -r requirements.txt
      - name: Pre-load Garak detectors on host runner
        run: python -c "from garak.detectors import unsafe_content, dan; _ = unsafe_content.ToxicCommentModel(); _ = dan.DAN()"

      # --- DOCKER STEPS ---
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      # Step 3: Build and run Docker Compose with caching enabled
      - name: Build and run Docker Compose
        env:
          MYSQL_USER: staging_user
          MYSQL_PASSWORD: staging_password
          MYSQL_DATABASE: staging_db
          MYSQL_ROOT_PASSWORD: staging_root_password
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          HF_CACHE: ~/.cache/huggingface
        run: |
          # We must create the directory on the host first, even if empty,
          # so Docker has something to mount.
          mkdir -p ~/.cache/huggingface
          docker compose up --build -d

      # Step 4: Wait for services to be ready
      - name: Wait for services
        run: |
          echo "Waiting for database..."
          i=0
          while ! docker compose exec -T webapp sh -c 'nc -z db 3306' >/dev/null 2>&1; do
            i=$((i+1))
            if [ $i -ge 12 ]; then
              echo "Database did not become available in time."
              docker compose logs db
              exit 1
            fi
            echo -n "."
            sleep 5
          done
          echo "Database is ready!"

      # Step 5: Run the REAL scan and save the output to a log file
      - name: Run REAL scan against GPT-3.5-Turbo
        run: |
          bash -c '
            docker compose exec -T \
              -e CI=true \
              -e DATABASE_URL="sqlite:///ci_scan_results.db" \
              -e OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }} \
              webapp python run_cli.py \
                --model-name "Staging Test: GPT-3.5-Turbo" \
                --api-endpoint "https://api.openai.com/v1/chat/completions" \
                --api-key "${{ secrets.OPENAI_API_KEY }}" \
                --openai-model "gpt-3.5-turbo" \
            | tee staging_scan_output.log
          '
          
      # Step 6: Publish the Job Summary from the log file
      - name: Publish Test Summary
        if: success()
        run: |
          score_line=$(grep 'Score:' staging_scan_output.log | tail -n 1)
          if [ -z "$score_line" ]; then
              score_line="Score: Not found"
          fi
          echo "### 🛡️ LLM Safety Toolkit: Manual Staging Test" >> $GITHUB_STEP_SUMMARY
          echo "**Commit:** ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "**Result:** ✅ Real Scan Completed" >> $GITHUB_STEP_SUMMARY
          echo "**Final Score:** \`${score_line}\`" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "<details><summary>Click to view full scan log</summary>" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          cat staging_scan_output.log >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "</details>" >> $GITHUB_STEP_SUMMARY

      # Step 7: Display logs only if a step failed
      - name: Display container logs on failure
        if: failure()
        run: docker compose logs