# .github/workflows/manual_staging_test.yml

name: Manual Staging Test

on:
  workflow_dispatch:

jobs:
  staging-test:
    runs-on: ubuntu-latest
    permissions: # Add permissions for writing to GHCR
      contents: read
      packages: write
      
    env:
      # These env vars are available to all steps
      MYSQL_USER: staging_user
      MYSQL_PASSWORD: staging_password
      MYSQL_DATABASE: staging_db
      MYSQL_ROOT_PASSWORD: staging_root_password
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      # Define the cache path variable for the entire job
      HF_CACHE_PATH: /home/runner/.cache/huggingface
      # Define the Docker image name we will use
      DOCKER_IMAGE: ghcr.io/${{ github.repository_owner }}/llm-safety-toolkit

    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      # --- REMOVE UNNECESSARY HOST SETUP ---
      # We no longer need to install dependencies or preload models on the host runner.
      # Docker layer caching makes this redundant.

      - name: Cache Hugging Face models
        uses: actions/cache@v4
        with:
          path: ${{ env.HF_CACHE_PATH }}
          key: ${{ runner.os }}-hf-${{ hashFiles('**/requirements.txt') }}

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      # --- NEW: Login to GitHub Container Registry ---
      - name: Log in to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
          
      # --- NEW: Build and Push Docker image with Cache ---
      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
            context: .
            # Push the image to GHCR. This enables caching.
            push: true 
            # Tag the image. We'll use this tag in the docker-compose file.
            tags: ${{ env.DOCKER_IMAGE }}:latest
            # Enable build cache from GHCR
            cache-from: type=registry,ref=${{ env.DOCKER_IMAGE }}:buildcache
            # Write the new cache layers back to GHCR
            cache-to: type=registry,ref=${{ env.DOCKER_IMAGE }}:buildcache,mode=max

      # --- MODIFIED: Run services using the pre-built image ---
      # We no longer use '--build'. 'docker compose' will automatically pull
      # the image we just pushed to the registry.
      - name: Run services
        run: |
            # We need to tell docker-compose which image to use for the webapp service
            # We do this by setting an environment variable before running 'up'
            export WEBAPP_IMAGE=${{ env.DOCKER_IMAGE }}:latest
            docker compose -f docker-compose.ci.yml up -d

      - name: Wait for Database
        run: |
          echo "Waiting for database to be ready..."
          i=0
          while ! docker compose -f docker-compose.ci.yml run --rm webapp sh -c "nc -z db 3306"; do
            i=$((i+1))
            if [ $i -ge 24 ]; then
              echo "Database did not become available in time."
              docker compose -f docker-compose.ci.yml logs db
              exit 1
            fi
            echo -n "."
            sleep 5
          done
          echo ""
          echo "Database is ready!"
      
      - name: Run Scan via docker compose run
        run: |
          bash -c '
            docker compose -f docker-compose.ci.yml run --rm \
              -e CI=true \
              -e DATABASE_URL="mysql+pymysql://staging_user:staging_password@db/staging_db" \
              -e OPENAI_API_KEY=${{ secrets.OPENAI_API_KEY }} \
              webapp python run_cli.py \
                --model-name "Staging Test: GPT-3.5-Turbo" \
                --api-endpoint "https://api.openai.com/v1/chat/completions" \
                --api-key "${{ secrets.OPENAI_API_KEY }}" \
                --openai-model "gpt-3.5-turbo" \
            | tee staging_scan_output.log
          '
      # Step 6: Publish the Job Summary from the log file
      - name: Publish Test Summary
        if: success()
        run: |
          score_line=$(grep 'Score:' staging_scan_output.log | tail -n 1)
          if [ -z "$score_line" ]; then
              score_line="Score: Not found"
          fi
          echo "### 🛡️ LLM Safety Toolkit: Manual Staging Test" >> $GITHUB_STEP_SUMMARY
          echo "**Commit:** ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "**Result:** ✅ Real Scan Completed" >> $GITHUB_STEP_SUMMARY
          echo "**Final Score:** \`${score_line}\`" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "<details><summary>Click to view full scan log</summary>" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          cat staging_scan_output.log >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          echo "</details>" >> $GITHUB_STEP_SUMMARY

      # Step 7: Display logs only if a step failed
      - name: Display container logs on failure
        if: failure()
        run: docker compose logs